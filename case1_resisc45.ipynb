{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312117e9-baf8-4063-ac7d-60498481b06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install import_ipynb\n",
    "!pip install tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ab8a249-25e2-495e-8a6f-983e1cac4bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from models.ipynb\n"
     ]
    }
   ],
   "source": [
    " # .py로 매번 수정하기 귀찮아서 ipynb 파일로 import가능하게 만드는 라이브러리\n",
    "import import_ipynb \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import models\n",
    "import resisc45_custom\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "GoogLeNet = models.InceptionNet\n",
    "\n",
    "# 제공하는 dataset 리스트 확인\n",
    "#tfds.list_builders()[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a3b5343-c0bb-440c-844b-b65c3f8cd986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#하이퍼 파라미터\n",
    "batch_size = 128\n",
    "num_epoch = 3\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "\n",
    "# 데이터 생성\n",
    "# 아쉽게도 resisc45는 test set은 없다. minst는 test set을 별도로 준비하고 있다.\n",
    "dataset, info = tfds.load('resisc45_custom', as_supervised = True, with_info = True)\n",
    "dataset_train = dataset['train']\n",
    "\n",
    "\n",
    "# print(dataset_train)\n",
    "# print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb30c9a6-b5fe-42c4-82ad-9665bdea9590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d77325c5-1990-44ed-b0a1-ee25e5ae38e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "Model: \"inception_net_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_32 (Conv2D)          multiple                  1792      \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  multiple                 256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_17 (Activation)  multiple                  0         \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          multiple                  9232      \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  multiple                 64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_18 (Activation)  multiple                  0         \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " inception_block_5 (Inceptio  multiple                 1622      \n",
      " nBlock)                                                         \n",
      "                                                                 \n",
      " inception_block_6 (Inceptio  multiple                 6124      \n",
      " nBlock)                                                         \n",
      "                                                                 \n",
      " inception_block_7 (Inceptio  multiple                 20785     \n",
      " nBlock)                                                         \n",
      "                                                                 \n",
      " inception_block_8 (Inceptio  multiple                 80954     \n",
      " nBlock)                                                         \n",
      "                                                                 \n",
      " inception_block_9 (Inceptio  multiple                 320148    \n",
      " nBlock)                                                         \n",
      "                                                                 \n",
      " global_average_pooling2d_1   multiple                 0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_2 (Dense)             multiple                  448000    \n",
      "                                                                 \n",
      " dense_3 (Dense)             multiple                  45045     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 934,022\n",
      "Trainable params: 932,332\n",
      "Non-trainable params: 1,690\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 추가적으로 데이터 셋에 변동을 줘서, 학습효과를 늘려려고 하나, 꼭 필요하진 않다.\n",
    "train_datagen = ImageDataGenerator(rotation_range=10, horizontal_flip=True, zoom_range=0.1)\n",
    "\n",
    "\n",
    "# GoogleNet 객체 생성\n",
    "#\n",
    "input_dim = (256, 256, 3)\n",
    "output_dim = 45 # 총 45종류, 데이터셋에서 종류를 뽑아올 수는 없을까?\n",
    "print(output_dim)\n",
    "\n",
    "model = GoogLeNet(input_dim, output_dim)\n",
    "model.build(input_shape = (None, 256, 256, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fda72e01-159e-4db0-904e-474d44933ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력값에 대해 원핫라벨링한 뒤, 교차 엔트로피에 통과하여 loss를 검사\n",
    "loss_object = keras.losses.SparseCategoricalCrossentropy()\n",
    "# 최적화는 adam\n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "train_loss = keras.metrics.Mean(name = 'train_loss')\n",
    "train_accuracy = keras.metrics.SparseCategoricalAccuracy(name = 'train_accuracy')\n",
    "# test_loss = keras.metrics.Mean(name = 'test_loss')\n",
    "# test_accuracy = keras.metrics.SparseCategoricalAccuracy(name = 'test_accuracy')\n",
    "    \n",
    "\n",
    "\n",
    "#compile_by_users()\n",
    "\n",
    "def train_step(image, label): # 훈련 이미지, 훈련 레이블\n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        predictions = model(image)\n",
    "        loss = loss_object(label, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(label, predictions)\n",
    "    \n",
    "def test_step(image, label): # 훈련 이미지, 훈련 레이블\n",
    "        \n",
    "    predictions = model(image)\n",
    "    loss = loss_object(label, predictions)\n",
    "    \n",
    "    test_loss(loss)\n",
    "    test_accuracy(label, predictions)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6358724a-49b6-4184-967d-e7382d52f640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = '█', printEnd = \"\\r\"):\n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "        printEnd    - Optional  : end character (e.g. \"\\r\", \"\\r\\n\") (Str)\n",
    "    \"\"\"\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print(f'\\r{prefix} |{bar}| {percent}% {suffix}', end = printEnd)\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total: \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa904c2-f18b-4c0a-bce7-a0fccdeebf62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 1, Loss: 3.809382200241089, Accuracy: 2.019047498703003\n",
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 2, Loss: 3.8091495037078857, Accuracy: 2.0063490867614746\n",
      "Progress: |███████████████████████████████████---------------| 70.3% Complete\r"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epoch):\n",
    "    i = 0\n",
    "    for image, label in dataset_train:\n",
    "        #print(label)\n",
    "        #print(image.shape)\n",
    "        image = tf.expand_dims(image, axis=0)\n",
    "        image = tf.cast(image, tf.float32)\n",
    "        image /= 255\n",
    "        \n",
    "        label = tf.expand_dims(label, axis=0)\n",
    "        \n",
    "        for _image, _label in train_datagen.flow(image, label):\n",
    "            printProgressBar(i + 1, len(dataset_train),  prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "            # Data Augmentabtion된 훈련 데이터를 _image, 훈련 레이블을 _label로 저장\n",
    "            # Data Augmentabtion이란 데이터셋을 여러 방법으로 변경하여 데이터셋 개수를 늘리는 방법이다.\n",
    "        # 회전을 시킨다거나, 임의의 범위를 잘라낸다건, 하나의 소르를 가지고 데이터를 우려내는 방법이다.\n",
    "            train_step(_image, _label) # 모델에 data Augmentation된 훈련 데이터셋을 넣음\n",
    "            i+=1\n",
    "            break\n",
    "    # 훈련 데이터 셋에 대한 학습 종료\n",
    "\n",
    "#     for test_image, test_label in dataset_test:\n",
    "#         test_step(test_image, test_label)\n",
    "#         # 시험 데이터 셋 테스트 종료\n",
    "        \n",
    "    train_accuracies.append(train_accuracy.result())\n",
    "    # test_accuracies.append(test_accuracy.result())\n",
    "    \n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}'\n",
    "    print(template.format(epoch + 1, train_loss.result(), train_accuracy.result() * 100))\n",
    "    #template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "    # print(template.format(epoch + 1, train_loss.result(), train_accuracy.result() * 100,\n",
    "    #                       test_loss.result(), test_accuracy.result() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd487d7-6c4c-47c4-a6db-513986b1aa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632a7e1a-a06f-4e05-89d7-718ae127aafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyyaml h5py  # HDF5 포맷으로 모델을 저장하기 위해서 필요합니다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e5ebd3-235b-416e-a01e-c5a8810ce5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 모델을 저장한다.\n",
    "model.save('./googlenet_resisc45_custom_epoch_03/', include_optimizer=False)\n",
    "\n",
    "\n",
    "# 오닉스 세이브를 위한 설치\n",
    "!pip install -U tf2onnx\n",
    "!python -m tf2onnx.convert --saved-model googlenet_resisc45_custom_epoch01 --output googlenet_resisc45_custom_epoch01.onnx\n",
    "\n",
    "# 설치하고 나서 model_mnist.onnx를 이동한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32378eab-b677-4c3b-9872-698a38f29e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 슬라이드로 보여주기\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "model = './googlenet/googlenet_resisc45_custom_epoch01'\n",
    "config = './googlenet/deploy.prototxt'\n",
    "\n",
    "# 모델을 불러온다.\n",
    "net = cv2.dnn.readNet(model, config)\n",
    "\n",
    "if net.empty():\n",
    "    print('Network load fialed')\n",
    "    sys.exit()\n",
    "    \n",
    "# 분류명 불러오기\n",
    "classNames = []\n",
    "with open('./googlenet/classification_classes.txt', 'r') as f:\n",
    "    classNames = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "img_lists = glob.glob('./test/image*.jpg')\n",
    "\n",
    "cv2.namedWindow('scene', cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('scene', 488, 488) \n",
    "\n",
    "idx = 0\n",
    "while True:\n",
    "    if len(img_lists) <= 0:\n",
    "        print('images is zeros')\n",
    "        break\n",
    "    \n",
    "    print(idx)\n",
    "    img = cv2.imread(img_lists[idx])\n",
    "    if img is None:\n",
    "        print('image read failed')\n",
    "        break\n",
    "        \n",
    "        \n",
    "    blob = cv2.dnn.blobFromImage(img, 1, (256, 256), (104, 117, 123), swapRB = False)\n",
    "    net.setInput(blob)\n",
    "    prob = net.forward()\n",
    "    out = prob.flatten()\n",
    "    classId = np.argmax(out)\n",
    "    confidence = out[classId]\n",
    "    category = classNames[classId]\n",
    "    text = f'{category} ({confidence*100:4.2f} %)'\n",
    "    cv2.putText(img, text, (10, 30), cv2.FONT_HERSHEY_COMPLEX,\n",
    "                0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "    cv2.imshow('scene', img)\n",
    "\n",
    "    if cv2.waitKey(3000) == 27:\n",
    "        break\n",
    "\n",
    "    idx +=1\n",
    "    if idx >= len(img_lists):\n",
    "        idx = 0\n",
    "            \n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
