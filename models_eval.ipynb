{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362feead-9fa3-4175-86e3-66d6698c1dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install import_ipynb\n",
    "!pip install tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52e9a30b-cf99-428e-80c3-c3a6e278ffa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from models.ipynb\n"
     ]
    }
   ],
   "source": [
    " # .py로 매번 수정하기 귀찮아서 ipynb 파일로 import가능하게 만드는 라이브러리\n",
    "import import_ipynb \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import models\n",
    "\n",
    "\n",
    "GoogLeNet = models.InceptionNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "612f4d6c-69c3-4a69-912f-9eee20624eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_net_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_96 (Conv2D)          multiple                  640       \n",
      "                                                                 \n",
      " batch_normalization_51 (Bat  multiple                 256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_51 (Activation)  multiple                  0         \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  multiple                 0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_97 (Conv2D)          multiple                  9232      \n",
      "                                                                 \n",
      " batch_normalization_52 (Bat  multiple                 64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_52 (Activation)  multiple                  0         \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  multiple                 0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " inception_block_15 (Incepti  multiple                 1622      \n",
      " onBlock)                                                        \n",
      "                                                                 \n",
      " inception_block_16 (Incepti  multiple                 6124      \n",
      " onBlock)                                                        \n",
      "                                                                 \n",
      " inception_block_17 (Incepti  multiple                 20785     \n",
      " onBlock)                                                        \n",
      "                                                                 \n",
      " inception_block_18 (Incepti  multiple                 80954     \n",
      " onBlock)                                                        \n",
      "                                                                 \n",
      " inception_block_19 (Incepti  multiple                 320148    \n",
      " onBlock)                                                        \n",
      "                                                                 \n",
      " global_average_pooling2d_3   multiple                 0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_6 (Dense)             multiple                  448000    \n",
      "                                                                 \n",
      " dense_7 (Dense)             multiple                  10010     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 897,835\n",
      "Trainable params: 896,145\n",
      "Non-trainable params: 1,690\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#하이퍼 파라미터\n",
    "batch_size = 128\n",
    "num_epoch = 100\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "\n",
    "def convert_types(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255\n",
    "    return image, label\n",
    "\n",
    "# 데이터 생성\n",
    "dataset, info = tfds.load('fashion_mnist', as_supervised = True, with_info = True)\n",
    "dataset_test, dataset_train = dataset['test'], dataset['train']\n",
    "\n",
    "\n",
    "dataset_train = dataset_train.map(convert_types).shuffle(10000).batch(batch_size)\n",
    "dataset_test = dataset_test.map(convert_types).batch(batch_size)\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=10, horizontal_flip=True, zoom_range=0.1)\n",
    "\n",
    "# GoogleNet 객체 생성\n",
    "model = GoogLeNet((28, 28, 1), 10)\n",
    "model.build(input_shape = (None, 28, 28, 1))\n",
    "model.summary()\n",
    "\n",
    "# Prepare Taining 라벨링\n",
    "\n",
    "############## #사용자 루프 모델 학습 ######\n",
    "# model.compile() 기능을 사용자가 직접 수동으로 하는 것\n",
    "#def compile_by_users():\n",
    "    \n",
    "# 입력값에 대해 원핫라벨링한 뒤, 교차 엔트로피에 통과하여 loss를 검사\n",
    "loss_object = keras.losses.SparseCategoricalCrossentropy()\n",
    "# 최적화는 adam\n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "train_loss = keras.metrics.Mean(name = 'train_loss')\n",
    "train_accuracy = keras.metrics.SparseCategoricalAccuracy(name = 'train_accuracy')\n",
    "test_loss = keras.metrics.Mean(name = 'test_loss')\n",
    "test_accuracy = keras.metrics.SparseCategoricalAccuracy(name = 'test_accuracy')\n",
    "    \n",
    "\n",
    "\n",
    "#compile_by_users()\n",
    "\n",
    "def train_step(image, label): # 훈련 이미지, 훈련 레이블\n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        predictions = model(image)\n",
    "        loss = loss_object(label, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(label, predictions)\n",
    "    \n",
    "def test_step(image, label): # 훈련 이미지, 훈련 레이블\n",
    "        \n",
    "    predictions = model(image)\n",
    "    loss = loss_object(label, predictions)\n",
    "    \n",
    "    test_loss(loss)\n",
    "    test_accuracy(label, predictions)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7f6d1b8-cf2c-41a2-aee6-64c4ab0adf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = '█', printEnd = \"\\r\"):\n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "        printEnd    - Optional  : end character (e.g. \"\\r\", \"\\r\\n\") (Str)\n",
    "    \"\"\"\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print(f'\\r{prefix} |{bar}| {percent}% {suffix}', end = printEnd)\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total: \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4480d49-bcb3-4922-aef7-9532bb4f2ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████--------------------------------| 37.7% Complete\r"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epoch):\n",
    "    i = 0\n",
    "    for image, label in dataset_train:\n",
    "        for _image, _label in datagen.flow(image, label, batch_size = batch_size):\n",
    "            printProgressBar(i + 1, len(dataset_train),  prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "            # Data Augmentabtion된 훈련 데이터를 _image, 훈련 레이블을 _label로 저장\n",
    "            # Data Augmentabtion이란 데이터셋을 여러 방법으로 변경하여 데이터셋 개수를 늘리는 방법이다.\n",
    "            # 회전을 시킨다거나, 임의의 범위를 잘라낸다건, 하나의 소르를 가지고 데이터를 우려내는 방법이다.\n",
    "            train_step(_image, _label) # 모델에 data Augmentation된 훈련 데이터셋을 넣음\n",
    "            i+=1\n",
    "            break\n",
    "    # 훈련 데이터 셋에 대한 학습 종료\n",
    "\n",
    "    for test_image, test_label in dataset_test:\n",
    "        test_step(test_image, test_label)\n",
    "        # 시험 데이터 셋 테스트 종료\n",
    "        \n",
    "    train_accuracies.append(train_accuracy.result())\n",
    "    test_accuracies.append(test_accuracy.result())\n",
    "    \n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "    print(template.format(epoch + 1, train_loss.result(), train_accuracy.result() * 100,\n",
    "                          test_loss.result(), test_accuracy.result() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc649b9-1b37-40f0-938b-a8d75c60957c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
